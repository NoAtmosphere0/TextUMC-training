{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example pipeline for fake news classification model\n",
    "Model link: https://huggingface.co/NoAtmosphere0/Roberta-large-fc\n",
    "\n",
    "Input: \n",
    "- claim (str): the claim to be classified\n",
    "- evidence (list[str]): a list of evidence that supports/refutes the claim\n",
    "\n",
    "Output:\n",
    "- label (str): the predicted label of the claim, either \"false\", \"half-true\", or \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_claim = \"The earth is flat.\" # Label: 0 (False)\n",
    "\n",
    "example_evidences = [\n",
    "    \"The documentary 'Behind the Curve' follows several Flat Earth advocates, documenting experiments they conducted to prove their claims. Ironically, many of their tests yielded results consistent with a spherical Earth, sparking debates among their community.\",\n",
    "    \"The Flat Earth Society continues to argue that the Earth is a flat disk, emphasizing that the horizon always appears level, regardless of altitude. Their members cite videos and photos taken at high altitudes, claiming no curvature is visible.\",\n",
    "    \"Recent satellite imagery and GPS technology rely on the Earth's spherical shape to function accurately. Scientists point to these systems as definitive evidence of Earth's roundness, highlighting that flat models cannot explain global positioning.\",\n",
    "    \"In a recent poll, 2% of respondents claimed they believe the Earth is flat, with many attributing their views to skepticism of mainstream science. However, the majority, 88%, affirmed the Earth is round, citing educational materials and personal observations.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(claim: str, evidences: str) -> str:\n",
    "    \"\"\"\n",
    "    Formats the input data into a dictionary for the fake news classifier.\n",
    "\n",
    "    The format looks like\n",
    "\n",
    "    ```python\n",
    "    Claim: {claim} </s> \\n Explanation: {evidence1} {evidence2} {evidence3} {evidence4}.\n",
    "    ```\n",
    "\n",
    "    Args:\n",
    "    claim (str): The claim to be classified.\n",
    "\n",
    "    evidences (List[str]): The evidences supporting the claim.\n",
    "\n",
    "    Returns:\n",
    "    str: The formatted input data.\n",
    "    \"\"\"\n",
    "    return f\"Claim: {claim} </s> \\n Explanation: {' '.join(evidences)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'false', 'score': 0.9998418092727661}]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pipe = pipeline(model=\"NoAtmosphere0/Roberta-large-fc\", device=device)\n",
    "\n",
    "# Classify the example claim\n",
    "result = pipe(format_input(example_claim, example_evidences))\n",
    "\n",
    "# Print the result\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example pipeline for hallucination checker\n",
    "Model link: https://huggingface.co/vectara/hallucination_evaluation_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0111, 0.6474, 0.1290, 0.8969, 0.1846, 0.0050, 0.0543])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "pairs = [ # Test data, List[Tuple[str, str]]\n",
    "    (\"The capital of France is Berlin.\", \"The capital of France is Paris.\"), # factual but hallucinated\n",
    "    ('I am in California', 'I am in United States.'), # Consistent\n",
    "    ('I am in United States', 'I am in California.'), # Hallucinated\n",
    "    (\"A person on a horse jumps over a broken down airplane.\", \"A person is outdoors, on a horse.\"),\n",
    "    (\"A boy is jumping on skateboard in the middle of a red bridge.\", \"The boy skates down the sidewalk on a red bridge\"),\n",
    "    (\"A man with blond-hair, and a brown shirt drinking out of a public water fountain.\", \"A blond man wearing a brown shirt is reading a book.\"),\n",
    "    (\"Mark Wahlberg was a fan of Manny.\", \"Manny was a fan of Mark Wahlberg.\")\n",
    "]\n",
    "\n",
    "# Step 1: Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'vectara/hallucination_evaluation_model', trust_remote_code=True)\n",
    "\n",
    "# Step 2: Use the model to predict\n",
    "model.predict(pairs) # note the predict() method. Do not do model(pairs). \n",
    "# tensor([0.0111, 0.6474, 0.1290, 0.8969, 0.1846, 0.0050, 0.0543])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
